# Docker Compose file Reference (https://docs.docker.com/compose/compose-file/)

version: '3'

# Define services
services:
  # App Service
  twitter-producer:
    container_name: twitter-ingest-container
    # Configuration for building the docker image for the service
    build:
      context: twitter-producer-svc # Use an image built from the specified dockerfile in the current directory.
      dockerfile: Dockerfile
    ports:
      - "8080:8080" # Forward the exposed port 8080 on the container to port 8080 on the host machine
    restart: unless-stopped
    
    depends_on: 
      - kafka-1 # This service depends on redis. Start that first.
    networks: # Networks to join (Services on the same network can communicate with each other using their name)
      - backend

  zookeeper-1:
    container_name: zookeeper-container
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 22181:2181

  # zookeeper-2:
  #   image: confluentinc/cp-zookeeper:latest
  #   environment:
  #     ZOOKEEPER_CLIENT_PORT: 2181
  #     ZOOKEEPER_TICK_TIME: 2000
  #   ports:
  #     - 32181:2181
  
  kafka-1:
    container_name: kafka-container
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper-1
      # - zookeeper-2

    ports:
      - 29092:29092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181,zookeeper-2:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      
  # kafka-2:
  #   image: confluentinc/cp-kafka:latest
  #   depends_on:
  #     - zookeeper-1
  #     - zookeeper-2
  #   ports:
  #     - 39092:39092
  #   environment:
  #     KAFKA_BROKER_ID: 2
  #     KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181,zookeeper-2:2181
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2:9092,PLAINTEXT_HOST://localhost:39092
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1


  spark-1:
    container_name: spark-container
    build:
      context: spark-svc # Use an image built from the specified dockerfile in the current directory.
      dockerfile: Dockerfile
    entrypoint: python /app/app.py
    restart: unless-stopped

  # es01:
  #   image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
  #   volumes:
  #     - data01:/usr/share/elasticsearch/data
  #   ports:
  #     - 9200:9200

  elasticsearch:
    container_name: elasticsearch-container
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
    environment:
      - xpack.security.enabled=false
      - "discovery.type=single-node"
    networks:
      - backend
    ports:
      - 9200:9200
    volumes:
      - data01:/usr/share/elasticsearch/data
  kibana:
    container_name: kibana-container
    image: docker.elastic.co/kibana/kibana:7.11.0
    environment:
      - ELASTICSEARCH_HOSTS=http://es-container:9200
    networks:
      - backend
    depends_on:
      - elasticsearch
    ports:
      - 5601:5601
networks:
  backend:
    driver: bridge


# networks:
#   backend:

# networks:
#   elastic:
#     driver: bridge
volumes:
  data01:
    driver: local